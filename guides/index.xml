<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Guides on Docker Docs</title>
    <link>https://docs.docker.com/guides/</link>
    <description>Recent content in Guides on Docker Docs</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="https://docs.docker.com/guides/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Build, tag, and publish an image</title>
      <link>https://docs.docker.com/guides/docker-concepts/building-images/build-tag-and-publish-an-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/building-images/build-tag-and-publish-an-image/</guid>
      <description>Explanation In this guide, you will learn the following:&#xA;Building images - the process of building an image based on a Dockerfile Tagging images - the process of giving an image a name, which also determines where the image can be distributed Publishing images - the process to distribute or share the newly created image using a container registry Building images Most often, images are built using a Dockerfile. The most basic docker build command might look like the following:</description>
    </item>
    <item>
      <title>Deploy to Kubernetes</title>
      <link>https://docs.docker.com/guides/deployment-orchestration/kube-deploy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/deployment-orchestration/kube-deploy/</guid>
      <description>Prerequisites Download and install Docker Desktop as described in Get Docker. Work through containerizing an application in Part 2. Make sure that Kubernetes is turned on in Docker Desktop: If Kubernetes isn&#39;t running, follow the instructions in Orchestration to finish setting it up. Introduction Now that you&#39;ve demonstrated that the individual components of your application run as stand-alone containers, it&#39;s time to arrange for them to be managed by an orchestrator like Kubernetes.</description>
    </item>
    <item>
      <title>Deploy to Swarm</title>
      <link>https://docs.docker.com/guides/deployment-orchestration/swarm-deploy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/deployment-orchestration/swarm-deploy/</guid>
      <description>Note&#xA;Swarm mode is an advanced feature for managing a cluster of Docker daemons.&#xA;Use Swarm mode if you intend to use Swarm as a production runtime environment.&#xA;If you&#39;re not planning on deploying with Swarm, use Docker Compose instead. If you&#39;re developing for a Kubernetes deployment, consider using the integrated Kubernetes feature in Docker Desktop.&#xA;Prerequisites Download and install Docker Desktop as described in Get Docker.&#xA;Work through containerizing an application in Docker workshop part 2</description>
    </item>
    <item>
      <title>Deployment and orchestration</title>
      <link>https://docs.docker.com/guides/deployment-orchestration/orchestration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/deployment-orchestration/orchestration/</guid>
      <description>Containerization provides an opportunity to move and scale applications to clouds and data centers. Containers effectively guarantee that those applications run the same way anywhere, allowing you to quickly and easily take advantage of all these environments. Additionally, as you scale your applications up, you need some tooling to help automate the maintenance of those applications, enable the replacement of failed containers automatically, and manage the roll-out of updates and reconfigurations of those containers during their lifecycle.</description>
    </item>
    <item>
      <title>Docker overview</title>
      <link>https://docs.docker.com/guides/docker-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-overview/</guid>
      <description>Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker&#39;s methodologies for shipping, testing, and deploying code, you can significantly reduce the delay between writing code and running it in production.&#xA;The Docker platform Docker provides the ability to package and run an application in a loosely isolated environment called a container.</description>
    </item>
    <item>
      <title>Educational resources</title>
      <link>https://docs.docker.com/guides/resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/resources/</guid>
      <description>Docker and the broader community of Docker experts have put together many different ways to get further training and hands-on experience with Docker. Expand your understanding of Docker and Kubernetes with these additional free and paid resources.&#xA;Docker Training Expand your knowledge on all things Docker with basic to advanced trainings from Docker experts.&#xA;You can find recorded content at your own convenience, or register for a live session to participate in Q&amp;amp;A.</description>
    </item>
    <item>
      <title>Multi-container applications</title>
      <link>https://docs.docker.com/guides/docker-concepts/running-containers/multi-container-applications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/running-containers/multi-container-applications/</guid>
      <description>Explanation Starting up a single-container application is easy. For example, a Python script that performs a specific data processing task runs within a container with all its dependencies. Similarly, a Node.js application serving a static website with a small API endpoint can be effectively containerized with all its necessary libraries and dependencies. However, as applications grow in size, managing them as individual containers becomes more difficult.&#xA;Imagine the data processing Python script needs to connect to a database.</description>
    </item>
    <item>
      <title>Multi-stage builds</title>
      <link>https://docs.docker.com/guides/docker-concepts/building-images/multi-stage-builds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/building-images/multi-stage-builds/</guid>
      <description>Explanation In a traditional build, all build instructions are executed in sequence, and in a single build container: downloading dependencies, compiling code, and packaging the application. All those layers end up in your final image. This approach works, but it leads to bulky images carrying unnecessary weight and increasing your security risks. This is where multi-stage builds come in.&#xA;Multi-stage builds introduce multiple stages in your Dockerfile, each with a specific purpose.</description>
    </item>
    <item>
      <title>Overriding container defaults</title>
      <link>https://docs.docker.com/guides/docker-concepts/running-containers/overriding-container-defaults/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/running-containers/overriding-container-defaults/</guid>
      <description>Explanation When a Docker container starts, it executes an application or command. The container gets this executable (script or file) from its image’s configuration. Containers come with default settings that usually work well, but you can change them if needed. These adjustments help the container&#39;s program run exactly how you want it to.&#xA;For example, if you have an existing database container that listens on the standard port and you want to run a new instance of the same database container, then you might want to change the port settings the new container listens on so that it doesn’t conflict with the existing container.</description>
    </item>
    <item>
      <title>Persisting container data</title>
      <link>https://docs.docker.com/guides/docker-concepts/running-containers/persisting-container-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/running-containers/persisting-container-data/</guid>
      <description>Explanation When a container starts, it uses the files and configuration provided by the image. Each container is able to create, modify, and delete files and does so without affecting any other containers. When the container is deleted, these file changes are also deleted.&#xA;While this ephemeral nature of containers is great, it poses a challenge when you want to persist the data. For example, if you restart a database container, you might not want to start with an empty database.</description>
    </item>
    <item>
      <title>Publishing and exposing ports</title>
      <link>https://docs.docker.com/guides/docker-concepts/running-containers/publishing-ports/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/running-containers/publishing-ports/</guid>
      <description>Explanation If you&#39;ve been following the guides so far, you understand that containers provide isolated processes for each component of your application. Each component - a React frontend, a Python API, and a Postgres database - runs in its own sandbox environment, completely isolated from everything else on your host machine. This isolation is great for security and managing dependencies, but it also means you can’t access them directly. For example, you can’t access the web app in your browser.</description>
    </item>
    <item>
      <title>Sharing local files with containers</title>
      <link>https://docs.docker.com/guides/docker-concepts/running-containers/sharing-local-files/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/running-containers/sharing-local-files/</guid>
      <description>Explanation Each container has everything it needs to function with no reliance on any pre-installed dependencies on the host machine. Since containers run in isolation, they have minimal influence on the host and other containers. This isolation has a major benefit: containers minimize conflicts with the host system and other containers. However, this isolation also means containers can&#39;t directly access data on the host machine by default.&#xA;Consider a scenario where you have a web application container that requires access to configuration settings stored in a file on your host system.</description>
    </item>
    <item>
      <title>Understanding the image layers</title>
      <link>https://docs.docker.com/guides/docker-concepts/building-images/understanding-image-layers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/building-images/understanding-image-layers/</guid>
      <description>Explanation As you learned in What is an image?, container images are composed of layers. And each of these layers, once created, are immutable. But, what does that actually mean? And how are those layers used to create the filesystem a container can use?&#xA;Image layers Each layer in an image contains a set of filesystem changes - additions, deletions, or modifications. Let’s look at a theoretical image:&#xA;The first layer adds basic commands and a package manager, such as apt.</description>
    </item>
    <item>
      <title>Using the build cache</title>
      <link>https://docs.docker.com/guides/docker-concepts/building-images/using-the-build-cache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/building-images/using-the-build-cache/</guid>
      <description>Explanation Consider the following Dockerfile that you created for the getting-started app.&#xA;FROM node:20-alpine WORKDIR /app COPY . . RUN yarn install --production CMD [&amp;#34;node&amp;#34;, &amp;#34;./src/index.js&amp;#34;] When you run the docker build command to create a new image, Docker executes each instruction in your Dockerfile, creating a layer for each command and in the order specified. For each instruction, Docker checks whether it can reuse the instruction from a previous build.</description>
    </item>
    <item>
      <title>What is a container?</title>
      <link>https://docs.docker.com/guides/docker-concepts/the-basics/what-is-a-container/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/the-basics/what-is-a-container/</guid>
      <description>Explanation Imagine you&#39;re developing a killer web app that has three main components - a React frontend, a Python API, and a PostgreSQL database. If you wanted to work on this project, you&#39;d have to install Node, Python, and PostgreSQL.&#xA;How do you make sure you have the same versions as the other developers on your team? Or your CI/CD system? Or what&#39;s used in production?&#xA;How do you ensure the version of Python (or Node or the database) your app needs isn&#39;t affected by what&#39;s already on your machine?</description>
    </item>
    <item>
      <title>What is a registry?</title>
      <link>https://docs.docker.com/guides/docker-concepts/the-basics/what-is-a-registry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/the-basics/what-is-a-registry/</guid>
      <description>Explanation Now that you know what a container image is and how it works, you might wonder - where do you store these images?&#xA;Well, you can store your container images on your computer system, but what if you want to share them with your friends or use them on another machine? That&#39;s where the image registry comes in.&#xA;An image registry is a centralized location for storing and sharing your container images.</description>
    </item>
    <item>
      <title>What is an image?</title>
      <link>https://docs.docker.com/guides/docker-concepts/the-basics/what-is-an-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/the-basics/what-is-an-image/</guid>
      <description>Explanation Seeing a container is an isolated process, where does it get its files and configuration? How do you share those environments?&#xA;That&#39;s where container images come in!&#xA;A container image is a standardized package that includes all of the files, binaries, libraries, and configurations to run a container.&#xA;For a PostgreSQL image, that image will package the database binaries, config files, and other dependencies. For a Python web app, it&#39;ll include the Python runtime, your app code, and all of its dependencies.</description>
    </item>
    <item>
      <title>What is Docker Compose?</title>
      <link>https://docs.docker.com/guides/docker-concepts/the-basics/what-is-docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/the-basics/what-is-docker-compose/</guid>
      <description>Explanation If you&#39;ve been following the guides so far, you&#39;ve been working with single container applications. But, now you&#39;re wanting to do something more complicated - run databases, message queues, caches, or a variety of other services. Do you install everything in a single container? Run multiple containers? If you run multiple, how do you connect them all together?&#xA;One best practice for containers is that each container should do one thing and do it well.</description>
    </item>
    <item>
      <title>Writing a Dockerfile</title>
      <link>https://docs.docker.com/guides/docker-concepts/building-images/writing-a-dockerfile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://docs.docker.com/guides/docker-concepts/building-images/writing-a-dockerfile/</guid>
      <description>Explanation A Dockerfile is a text-based document that&#39;s used to create a container image. It provides instructions to the image builder on the commands to run, files to copy, startup command, and more.&#xA;As an example, the following Dockerfile would produce a ready-to-run Python application:&#xA;FROM python:3.12 WORKDIR /usr/local/app # Install the application dependencies COPY requirements.txt ./ RUN pip install --no-cache-dir -r requirements.txt # Copy in the source code COPY src .</description>
    </item>
  </channel>
</rss>
